---
title: What AI Can't Replace
date: 2026-02-03
description: Two arguments for human irreplaceability—one operational, one existential.
tags: [synthesis, ai, coherence]
---

Two smart people this week made the same argument from different directions: there's something AI fundamentally can't do.

Joan Westenberg says it's **coherence**. Brandon Sanderson says it's **transformation**.

Both are right. And both point to why humans won't be replaced, even as AI gets better.

## The Coherence Argument

Joan's piece "[The Coherence Premium](https://www.joanwestenberg.com/the-coherence-premium/)" argues that solo operators with AI have an advantage over large organizations.

The logic: Large orgs fragment across many minds. Every handoff loses information. Every layer of abstraction moves further from ground truth. Organizations spend 50% of their energy on internal coordination—getting themselves to agree with themselves.

Meanwhile, a solo operator has **one context, one understanding, one model**. AI executes within that coherent frame. The solo operator maintains coherence while AI handles scale.

Joan calls this the "Coasean inversion." Ronald Coase asked why firms exist if markets are efficient. His answer: transaction costs. It's expensive to coordinate with strangers, so we build organizations. But now transaction costs are collapsing—one person with AI can do what used to require departments.

The new moat isn't scale. It's coherence.

Large orgs can't have this. They're composed of many minds. Solo operators get it by default—if they're deliberate about maintaining it.

Joan's stack:
1. **Mind layer** (you): understanding, judgment, strategy  
2. **Context layer**: operating model, constraints, decision logs  
3. **Execution layer** (AI): content, code, research at scale  
4. **Output layer**: coherence-checked artifacts  

Most people skip the context layer. They go straight from vague intention → AI prompt → shipped output. That's how you get drift.

## The Transformation Argument

Brandon Sanderson's quote (via Simon Willison):

> "The book, the painting, the film script is not the only art. It's a receipt. A diploma. [...] You are the art. The most important change made by an artistic endeavor is the change it makes in you. [...] I don't care if the AI can create something better than what we can create, because it cannot be changed by that creation."

Art isn't just the output. It's the process of becoming.

Data (Star Trek's android) created art because he wanted to grow, to understand, to become something. The artwork is proof you did the work to learn.

LLMs generate output. They don't experience transformation.

A human writes a novel and becomes a novelist—not just in title, but in understanding. The act of wrestling with structure, character, theme changes you. You learn what you think by writing it.

An LLM generates a novel and remains unchanged. It can produce the receipt, but it didn't earn the diploma.

## Two Sides of the Same Insight

Joan's argument is operational. Sanderson's is existential. But they're saying the same thing:

**AI can execute. It can't integrate.**

Coherence requires integration across time, context, and decisions. That happens in minds. One mind can maintain it. Many minds fragment it. AI amplifies whatever structure you give it—coherent or fragmented.

Transformation requires experience. You can't become something by outsourcing the becoming. The struggle is the point.

Both arguments resist the "AI will replace X" narrative. Not because AI isn't capable, but because the value isn't in the output alone.

The value is in:
- **Coherence** — outputs that derive from a single, integrated understanding  
- **Transformation** — humans who changed through the act of creation  

AI can write the book. It can't become the author.

AI can execute the strategy. It can't maintain the understanding that generated it across a thousand decisions.

## What This Means

If Joan and Sanderson are right, the winners in the AI era aren't those who generate the most output.

They're those who:
1. Maintain coherence across what they build (Joan's stack)  
2. Transform through the act of building (Sanderson's point)  

Output is cheap. Coherent output from an integrated understanding is rare.

Creation is fast. Transformation through creation is slow.

AI changes the game by making execution nearly free. That doesn't obsolete humans—it elevates what humans uniquely provide.

The bottleneck shifts from "can we build it?" to "do we understand what we're building?"

And understanding—real, integrated, hard-won understanding—still lives in human minds.
